目标：
进行车辆分类，然后选取合适的充电头

transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
求矩阵和方差
transforms.Scale(60)
将图片缩放为60*60
transforms.RandomCrop(48)
将图片裁剪为48*48的大小
transforms.RandomHorizontalFlip(),
将图片左右翻转
transforms.RandomRotation(10),
将图片旋转10度


traindataloader = torchvision.utils.data.Dataloade(traindataset,batch_size = 16, shuffle = True, num_workers = 1)
valdataloader = torchvision.utils.data.Dataloade(valdataset,batch_size = 16, shuffle = False, num_workers = 1)
数据指针


这个错误信息通常出现在使用Python的multiprocessing模块创建子进程时。错误的根本原因是在主模块启动子进程之前，当前进程尚未完成引导阶段。这可能是由于在主模块中未正确使用`if __name__ == '__main__':`条件判断和`freeze_support()`函数引起的。

在Python中，当你启动一个新的进程时，它会尝试将整个主程序复制到新的进程中。为了避免无限递归复制，Python使用`fork`系统调用或者其他方法来启动新进程。然而，在某些情况下，特别是在Windows系统上，这种机制可能导致上述错误。

为了解决这个问题，你应该在主模块中使用`if __name__ == '__main__':`条件判断，确保只有在直接运行脚本时才会执行子进程创建的代码。并且，如果你在Windows上运行，还需要调用`freeze_support()`函数，它会在冻结（freeze）程序以生成可执行文件时执行必要的初始化工作。

以下是一个简单的例子：

```python
from multiprocessing import Process, freeze_support

def my_function():
    print("This is a function in the child process.")

if __name__ == '__main__':
    # 在Windows上调用freeze_support()
    freeze_support()

    # 在主模块中创建子进程
    my_process = Process(target=my_function)
    my_process.start()
    my_process.join()
```

这个例子中，`freeze_support()`在Windows上是必需的，确保在生成可执行文件时不会出现上述错误。在其他平台上，它可以被忽略。



`IndentationError: expected an indented block` 是Python的语法错误之一，表示在代码中期望一个缩进块（indented block），但没有找到。在Python中，代码块通过缩进来定义，而不是使用花括号或其他关键字符。

这个错误通常出现在控制流程语句（如if、for、while等）或函数定义后面，因为它们后面应该紧跟一个缩进的代码块。例如：

```python
if condition:
# 这里应该有一个缩进的代码块，如果没有会引发IndentationError
```

或者：

```python
def my_function():
# 这里应该有一个缩进的代码块，如果没有会引发IndentationError
```

要解决这个错误，你需要在控制流程语句或函数定义后添加缩进的代码块。确保缩进的空格数目一致，通常是使用4个空格或者一个制表符。例如：

```python
if condition:
    # 这是一个缩进的代码块
    print("Inside the if block")
```

或者：

```python
def my_function():
    # 这是一个缩进的代码块
    print("Inside the function")
```

请检查你的代码，找到出现错误的位置，确保在需要缩进的地方添加正确的缩进。这种错误通常是由于缩进不正确或者混用了空格和制表符引起的。



这个错误是由于在使用PyTorch的`torchvision`库进行图像转换时，遇到了一个值错误（ValueError）。具体来说，错误信息指出了问题发生在将图像从RGB模式转换为灰度模式时，要求`num_output_channels`参数的值应为1或3，但提供的值不符合要求。

在你的代码的堆栈中，错误发生在`torchvision.transforms.functional.rgb_to_grayscale`函数中。这个函数调用`F_pil.to_grayscale`函数，而在这个函数中，`num_output_channels`的值应为1或3。然而，你提供了一个不合适的值，导致抛出了值错误。

为了解决这个问题，你需要检查你的图像转换代码，确保在调用`rgb_to_grayscale`时，传递的`num_output_channels`参数的值是1或3。你可以修改相关代码，使其符合要求。例如：

```python
# 示例代码
transform = transforms.Compose([
    # 其他的转换操作
    transforms.Grayscale(num_output_channels=1),  # 或者 num_output_channels=3
    # 其他的转换操作
])
```

确保你在图像转换中的相关参数设置是符合要求的，避免传递不正确的参数值。



这个错误表明在数据加载和转换过程中发生了形状不匹配的问题。具体地说，错误信息中提到的是在执行图像标准化（normalize）时出现了问题。

在PyTorch的`torchvision.transforms.Normalize`中，标准化操作需要指定均值（mean）和标准差（std）。通常，这些均值和标准差是为R++GB图像设计的，因此期望输入张量的通道数为3。

然而，在你的情况下，错误信息中显示的输入张量形状是 `[1, 48, 48]`，这表示它是一个单通道（灰度）图像，而标准化操作期望的是具有3个通道的张量。

要解决这个问题，你可以检查图像的通道数是否符合标准化操作的预期。如果你的数据集中包含单通道图像，你可能需要根据实际情况调整图像标准化的方式。以下是一种可能的解决方法：

```python
# 示例代码
transform = transforms.Compose([
    # 其他的转换操作
    transforms.ToTensor(),  # 确保图像被转换为张量
    transforms.Normalize(mean=[0.5], std=[0.5]),  # 使用适当的均值和标准差
    # 其他的转换操作
])
```

在这个示例中，`transforms.Normalize`的`mean`和`std`参数都是长度为1的列表，适应单通道图像。确保你根据实际的图像通道数设置正确的均值和标准差。


class MyDataset(dataset):
    def __init__(self,datatxt,datatransform):
        datas = open(datatxt,'r').readlines()
        self.images = []
        self.labels = []
        for data in datas:
            item = data.strip().split(' ')
            self.images.append(item[0])
            self.labels.append(item[1])
        print('number of datas = '+str(len(self.images)))
        return

    def __len__(self):
        return len(self.images)

    def __getitem__(self, item):
        image,label = self.images[item],self.labels[item]
        return len(self.images)

在较大的项目中可以自己进行定义类


# 姓名：孙圣雷
# 开发时间：2023/12/4 18:34
import torch
import torch.nn as nn
import torch.nn.functional as F

class simpleconv3(nn.Module):
    def __init__(self):
        super(simpleconv3,self).__init__()
        return

    def forward(self):
        return


基本框架，如上



number of datas900
number of datas900
训练集数据总数=900
验证集数据总数=900
epoch=0 loss=0.6931932051976522 acc=0.5020833333333333
epoch=1 loss=0.6922783255577087 acc=0.5114583333333333
epoch=2 loss=0.6859095017115275 acc=0.5447916666666667
epoch=3 loss=0.6868293841679891 acc=0.5520833333333334
epoch=4 loss=0.6730340758959452 acc=0.5802083333333333
epoch=5 loss=0.6453017592430115 acc=0.6333333333333333
epoch=6 loss=0.6408464471499126 acc=0.6541666666666667
epoch=7 loss=0.6742401719093323 acc=0.575
epoch=8 loss=0.66459721326828 acc=0.6145833333333334
epoch=9 loss=0.6023455222447713 acc=0.6635416666666667
epoch=10 loss=0.5752677003542582 acc=0.6958333333333333
epoch=11 loss=0.5612881561120351 acc=0.7177083333333333
epoch=12 loss=0.6135976433753967 acc=0.6864583333333333
epoch=13 loss=0.5446876406669616 acc=0.7322916666666667
epoch=14 loss=0.5472048759460449 acc=0.7114583333333333
epoch=15 loss=0.6442533254623413 acc=0.6395833333333333
epoch=16 loss=0.521116332213084 acc=0.73125
epoch=17 loss=0.5564551293849945 acc=0.728125
epoch=18 loss=0.5567348559697469 acc=0.725
epoch=19 loss=0.5339653154214223 acc=0.7447916666666666

进程已结束，退出代码为 0
















dataset.py:
这段代码是一个用于处理图像数据的 PyTorch 数据加载和预处理的脚本。下面是对代码的解释和作用的说明：

1. **导入库：**
   ```python
   import torch
   import torchvision
   import torchvision.datasets as datasets
   import torchvision.transforms as transforms
   from PIL import Image
   ```
   这里导入了 PyTorch 相关的库，以及用于处理图像的 `PIL` 库。

2. **定义数据转换（Transforms）：**
   ```python
   traindata_transformer = transforms.Compose([
       transforms.RandomCrop(48),
       transforms.Grayscale(3),
       transforms.RandomHorizontalFlip(),
       transforms.RandomRotation(10),
       transforms.ToTensor(),
       transforms.Normalize((0.5), (0.5)),
   ])

   valdata_transformer = transforms.Compose([
       transforms.Grayscale(3),
       transforms.ToTensor(),
       transforms.Normalize((0.5), (0.5)),
   ])
   ```
   `transforms.Compose` 允许将多个数据转换操作组合在一起。在这里，定义了训练数据和验证数据的转换操作，包括裁剪、灰度化、水平翻转、随机旋转、转为张量（tensor）、以及归一化。

3. **自定义数据集类 `MyDataset`：**
   ```python
   class MyDataset(torch.utils.data.Dataset):
       def __init__(self, datatxt, datatransform):
           # 读取数据文件，每行包含图像路径和标签，按空格分隔
           datas = open(datatxt, 'r').readlines()
           self.images = []
           self.labels = []
           self.transform = datatransform

           # 将数据文件中的路径和标签分别存储在 self.images 和 self.labels 中
           for data in datas:
               item = data.strip().split(' ')
               self.images.append(item[0])
               self.labels.append(item[1])

       def __len__(self):
           return len(self.images)

       def __getitem__(self, item):
           # 根据索引加载图像并应用数据转换
           image_path, label = self.images[item], self.labels[item]
           image = Image.open(image_path)
           return self.transform(image), int(label)
   ```
   这个类用于自定义数据集，其中包含了两个方法：`__init__` 初始化方法用于读取数据文件，`__getitem__` 方法用于加载图像并应用数据转换。

4. **数据集实例化：**
   ```python
   traintxt = 'data/train.txt'
   vsltxt = 'data/val.txt'
   traindataset = MyDataset(traintxt, traindata_transformer)
   valdataset = MyDataset(vsltxt, valdata_transformer)
   ```
   创建了训练集和验证集的实例，传入了数据文件路径和相应的数据转换器。

5. **数据加载器的配置：**
   ```python
   traindataloader = torch.utils.data.DataLoader(traindataset, batch_size=16, shuffle=True, num_workers=1)
   valdataloader = torch.utils.data.DataLoader(valdataset, batch_size=16, shuffle=False, num_workers=1)
   ```
   使用 `torch.utils.data.DataLoader` 将数据集包装成一个迭代器，用于遍历整个数据集。这里设置了批量大小为 16，训练集进行了打乱操作 (`shuffle=True`)。

6. **遍历数据集：**
   ```python
   for sample in traindataloader:
       print(type(sample[0]))
       print(sample[0].shape)  # 取数据
       print(type(sample[1]))
       print(sample[1].shape)  # 取标签
   ```
   通过数据加载器遍历训练集，输出每个批次的数据类型、形状以及标签。这可以用于验证数据加载和转换是否按预期工作。


Net.py:
这段代码定义了一个简单的卷积神经网络模型 `simpleconv3`。下面是对代码的解释：

1. **导入 PyTorch 模块：**
   ```python
   import torch
   import torch.nn as nn
   import torch.nn.functional as F
   ```
   导入 PyTorch 中用于神经网络构建的模块。

2. **定义神经网络模型 `simpleconv3`：**
   ```python
   class simpleconv3(nn.Module):
       def __init__(self, classes):
           super(simpleconv3, self).__init__()
           # 定义卷积层
           self.conv1 = nn.Conv2d(3, 16, 3, 2, 1)  # 3*3的卷积步长为2
           self.conv2 = nn.Conv2d(16, 32, 3, 2, 1)  # 3*3的卷积步长为2
           self.conv3 = nn.Conv2d(32, 64, 3, 2, 1)  # 3*3的卷积步长为2
           # 定义全连接层
           self.fc1 = nn.Linear(2304, 100)  # 48*48*3 -> 24*24*16 -> 12*12*32 -> 6*6*64 (最后一个乘数为通道数)
           self.fc2 = nn.Linear(100, classes)

       def forward(self, x):
           # 定义前向传播过程
           x = F.relu(self.conv1(x))
           x = F.relu(self.conv2(x))
           x = F.relu(self.conv3(x))
           x = x.view(-1, 2304)
           x = F.relu(self.fc1(x))
           x = self.fc2(x)
           return x
   ```
   这个模型包含了三个卷积层和两个全连接层。卷积层的参数中，`nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)` 分别表示输入通道数、输出通道数、卷积核大小、步长和填充。全连接层的参数是输入和输出的节点数。

3. **模型实例化和前向传播：**
   ```python
   if __name__ == '__main__':
       input = torch.rand((3, 48, 48))
       net = simpleconv3(2)  # 创建模型实例，2 表示输出的类别数
       output = net(input)
       print(output)
   ```
   在主程序中，创建了模型实例 `net`，并通过输入数据 `input` 进行前向传播，输出模型的预测结果。

注意：
- 输入数据的大小是 (3, 48, 48)，表示3个通道，每个通道大小为48x48的图像。
- 模型的输出是一个经过全连接层处理的向量，其大小与类别数有关，这里是2类（二分类），因此输出是大小为2的向量。



对Net.py的优化:
Batch Normalization：

在卷积层后面添加Batch Normalization层，有助于加速模型训练过程，并有一定的正则化效果，可以提高模型的泛化能力。
更深的网络结构：

考虑增加卷积层和全连接层的数量，以增加网络的深度，有助于提取更复杂的特征。
Dropout：

在全连接层之间添加Dropout层，有助于防止过拟合，提高模型的泛化能力。
使用更小的卷积核：

考虑使用较小的卷积核，例如3x3的卷积核，可以增加非线性表达能力，并减少模型参数数量。
学习率调度器：

使用学习率调度器，如StepLR或ReduceLROnPlateau，有助于在训练过程中自适应地调整学习率，提高训练效果。
合适的激活函数：

根据任务的需要选择适当的激活函数，例如ReLU、Leaky ReLU或者GELU等。
更多的数据增强：

在数据加载时增加更多的数据增强操作，如随机旋转、随机剪裁等，有助于增加模型的鲁棒性。
权重初始化：

使用合适的权重初始化策略，如He初始化，有助于加速模型的收敛。




train.py:
这段代码是一个简单的深度学习模型的训练脚本，其中包含了数据加载、模型定义、训练、保存模型、导出ONNX模型和绘制训练曲线等步骤。以下是对代码的主要部分的解释：

1. **导入相关模块：**
   ```python
   from dataset import MyDataset
   from Net import simpleconv3

   import torch
   import torch.nn as nn
   import torch.nn.functional as F

   import torch
   import torchvision
   import torch.utils.data.dataset as dataset
   import torchvision.datasets as datasets
   import torchvision.transforms as transforms
   from torch.optim import SGD
   from torch.optim.lr_scheduler import StepLR
   from PIL import Image
   import matplotlib.pyplot as plt
   ```
   导入了与数据处理、模型定义、PyTorch模块、优化器等相关的库。

2. **数据处理和加载：**
   ```python
   traindata_transformer = transforms.Compose([...])  # 训练集数据变换
   valdata_transformer = transforms.Compose([...])    # 验证集数据变换

   traintxt = 'data/train.txt'
   vsltxt = 'data/val.txt'
   traindataset = MyDataset(traintxt, traindata_transformer)
   valdataset = MyDataset(vsltxt, valdata_transformer)
   traindataloader = torch.utils.data.DataLoader(traindataset, batch_size=64, shuffle=True, num_workers=1)
   valdataloader = torch.utils.data.DataLoader(valdataset, batch_size=64, shuffle=False, num_workers=1)
   ```
   定义了数据的变换操作和创建了训练集和验证集的数据加载器。

3. **模型定义和训练：**
   ```python
   Net = simpleconv3(2)  # 创建模型
   optim = SGD(Net.parameters(), lr=0.01, momentum=0.9)  # 定义优化器
   criterion = torch.nn.CrossEntropyLoss()  # 定义损失函数
   lr_step = StepLR(optim, step_size=100, gamma=0.1)  # 学习率调整器

   epochs = 100
   accs = []
   losss = []

   for epoch in range(0, epochs):
       # 训练过程
       for data in traindataloader:
           # 省略...

   # 保存模型
   torch.save(Net, 'model.pth')
   ```

4. **导出ONNX模型：**
   ```python
   x = torch.randn(1, 3, 48, 48)
   net = torch.load('model.pth')
   Net.train(False)
   torch.onnx.export(net, x, 'model.onnx')
   ```

5. **绘制训练曲线：**
   ```python
   plt.plot(range(len(accs)), accs)
   plt.plot(range(len(losss)), losss)
   plt.xlabel('epoch')
   plt.legend(('acc', 'loss'))
   plt.show()
   ```
   绘制训练过程中的准确率和损失的变化曲线。

这段代码的主要目的是定义一个简单的卷积神经网络模型，对其进行训练，并保存训练好的模型。同时，通过ONNX导出模型，以便在其他框架中使用。


dataset.py:
这段代码主要用于创建自定义的数据集类，并使用PyTorch中的数据加载器（DataLoader）来加载训练集和验证集的数据。以下是代码的一些优点：

1. **数据增强（Data Augmentation）：**
   - 通过使用transforms.Compose()函数，对训练集数据进行了数据增强操作，如随机裁剪、灰度化、水平翻转和随机旋转等。这有助于提高模型的泛化能力，防止过拟合。

2. **自定义数据集类：**
   - 创建了一个自定义的数据集类（MyDataset），该类继承自`torch.utils.data.Dataset`，实现了`__len__`和`__getitem__`方法，使得可以按照PyTorch的数据加载器要求加载数据。这样可以方便地处理特定格式的数据集。

3. **数据加载器：**
   - 使用`torch.utils.data.DataLoader`来加载数据集，这样可以方便地迭代获取小批量的数据。这对于训练深度学习模型是必要的，尤其是当数据集很大时。

4. **标准化：**
   - 在数据预处理中进行了标准化操作，使用了transforms.Normalize()函数。这有助于加速模型的训练过程，使其更容易收敛。

5. **代码结构清晰：**
   - 代码结构相对清晰，按照常见的PyTorch数据加载流程组织。模块化的结构使得代码易于理解和维护。

6. **扩展性：**
   - 通过自定义数据集类，可以轻松地扩展到其他数据集，只需提供新的数据集文件和相应的预处理操作。

7. **数据加载并行：**
   - 通过设置`num_workers`参数，可以实现数据加载的并行化，提高数据加载效率。

8. **合理的批量大小：**
   - 使用了适当的批量大小，这有助于充分利用GPU并行性能，提高训练效率。

要注意的是，代码的效果还取决于具体任务和数据集。以上是一般性的优点，具体应用中可能需要根据任务和数据集的特点进行调整。



Net.py
这段代码定义了一个简单的卷积神经网络模型（`simpleconv3`），主要用于图像分类任务。以下是代码的一些优点：

1. **模型结构清晰：**
   - 模型结构简单明了，由三个卷积层和两个全连接层组成，便于理解和调试。

2. **卷积层和全连接层的使用：**
   - 使用了卷积层进行特征提取，通过逐渐减小空间维度和增加通道数，有助于捕捉图像中的层次化特征。
   - 利用全连接层进行分类，将卷积层提取的特征映射到类别空间，适用于图像分类任务。

3. **激活函数的使用：**
   - 在卷积层之后使用了ReLU激活函数，有助于引入非线性，增加模型的表达能力。

4. **模型参数的自动计算：**
   - 在全连接层中，输入特征的数量（`2304`）是通过计算得到的，而不是手动设置。这种自动计算使得模型更具有通用性，不需要手动调整参数。

5. **模型可配置性：**
   - 通过构造函数中的`classes`参数，可以轻松地配置模型输出的类别数目。

6. **代码注释：**
   - 提供了简要的注释，有助于理解每个模块的作用和结构。

7. **适用于小尺寸图像：**
   - 适用于输入尺寸为`48x48`的图像，通过卷积和池化操作逐渐减小特征图的空间维度。

8. **PyTorch风格：**
   - 代码符合PyTorch的模型定义风格，易于与其他PyTorch模型集成和使用。

要注意的是，具体任务和数据集可能需要调整模型结构和超参数。此模型适用于小规模图像分类任务，对于更复杂的任务，可能需要更深层次的网络结构和更复杂的特征提取。

Net.py解释：

```python
class simpleconv3(nn.Module):
    def __init__(self, classes):
        super(simpleconv3, self).__init__()
        # 卷积层1，输入通道数为3（RGB），输出通道数为16，卷积核大小为3，步长为2，padding为1
        self.conv1 = nn.Conv2d(3, 16, 3, 2, 1)
        # 卷积层2，输入通道数为16，输出通道数为32，卷积核大小为3，步长为2，padding为1
        self.conv2 = nn.Conv2d(16, 32, 3, 2, 1)
        # 卷积层3，输入通道数为32，输出通道数为64，卷积核大小为3，步长为2，padding为1
        self.conv3 = nn.Conv2d(32, 64, 3, 2, 1)
        # 全连接层1，输入特征数为2304（6*6*64），输出特征数为100
        self.fc1 = nn.Linear(2304, 100)
        # 全连接层2，输入特征数为100，输出特征数为classes（模型输出的类别数）
        self.fc2 = nn.Linear(100, classes)

    def forward(self, x):
        # 通过卷积层1并应用ReLU激活函数
        x = F.relu(self.conv1(x))
        # 通过卷积层2并应用ReLU激活函数
        x = F.relu(self.conv2(x))
        # 通过卷积层3并应用ReLU激活函数
        x = F.relu(self.conv3(x))
        # 将特征展平成一维向量
        x = x.view(-1, 2304)
        # 通过全连接层1并应用ReLU激活函数
        x = F.relu(self.fc1(x))
        # 通过全连接层2获得最终输出
        x = self.fc2(x)
        return x


if __name__ == '__main__':
    # 创建一个随机输入张量，代表一张尺寸为(3, 48, 48)的RGB图像
    input = torch.rand((3, 48, 48))
    # 创建一个simpleconv3模型，输出类别数为2
    net = simpleconv3(2)
    # 将输入张量传递给模型，获得模型输出
    output = net(input)
    # 打印模型输出
    print(output)
```

上述代码主要包括以下几个部分：

1. **模型定义部分 (`simpleconv3` 类)：**
   - 模型继承自`nn.Module`类，该类是PyTorch中所有模型的基类。
   - 构造函数中定义了卷积层 (`nn.Conv2d`) 和全连接层 (`nn.Linear`)。
   - `forward` 方法定义了前向传播过程，包括卷积操作、ReLU激活函数和全连接操作。

2. **模型使用部分 (`if __name__ == '__main__':`)：**
   - 创建一个随机输入张量 `input`，代表一张尺寸为(3, 48, 48)的RGB图像。
   - 创建一个 `simpleconv3` 模型，输出类别数为2。
   - 将输入张量传递给模型，获得模型输出 `output`。
   - 打印模型输出。

3. **卷积层和全连接层的参数：**
   - `nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)`：定义一个二维卷积层，包括输入通道数、输出通道数、卷积核大小、步长和填充。
   - `nn.Linear(in_features, out_features)`：定义一个全连接层，包括输入特征数和输出特征数。

4. **激活函数：**
   - 使用了ReLU激活函数 (`F.relu`)，以引入非线性特征。

5. **模型输出：**
   - 模型的输出是通过 `forward` 方法计算得到的，表示模型对输入的预测结果。





Fresh_Train_Data
C:\Users\Lenovo\opencv\Scripts\python.exe G:\chager_train\Fresh_train.py
number of datas900
number of datas900
训练集数据总数=900
验证集数据总数=900
C:\Users\Lenovo\opencv\lib\site-packages\torch\optim\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch 0/50 - Loss: 0.7029 - Acc: 0.5521
Epoch 1/50 - Loss: 0.6262 - Acc: 0.6573
Epoch 2/50 - Loss: 0.5849 - Acc: 0.7063
Epoch 3/50 - Loss: 0.5667 - Acc: 0.6979
Epoch 4/50 - Loss: 0.5137 - Acc: 0.7594
Epoch 5/50 - Loss: 0.5003 - Acc: 0.7583
Epoch 6/50 - Loss: 0.4859 - Acc: 0.7688
Epoch 7/50 - Loss: 0.4824 - Acc: 0.7906
Epoch 8/50 - Loss: 0.4246 - Acc: 0.8240
Epoch 9/50 - Loss: 0.4558 - Acc: 0.7854
Epoch 10/50 - Loss: 0.4386 - Acc: 0.8125
Epoch 11/50 - Loss: 0.3991 - Acc: 0.8385
Epoch 12/50 - Loss: 0.4214 - Acc: 0.8354
Epoch 13/50 - Loss: 0.3937 - Acc: 0.8458
Epoch 14/50 - Loss: 0.3965 - Acc: 0.8198
Epoch 15/50 - Loss: 0.4363 - Acc: 0.8000
Epoch 16/50 - Loss: 0.4181 - Acc: 0.8187
Epoch 17/50 - Loss: 0.3447 - Acc: 0.8594
Epoch 18/50 - Loss: 0.3557 - Acc: 0.8354
Epoch 19/50 - Loss: 0.3698 - Acc: 0.8365
Epoch 20/50 - Loss: 0.3642 - Acc: 0.8406
Epoch 21/50 - Loss: 0.3359 - Acc: 0.8646
Epoch 22/50 - Loss: 0.3737 - Acc: 0.8396
Epoch 23/50 - Loss: 0.3342 - Acc: 0.8688
Epoch 24/50 - Loss: 0.3135 - Acc: 0.8719
Epoch 25/50 - Loss: 0.3466 - Acc: 0.8573
Epoch 26/50 - Loss: 0.3304 - Acc: 0.8594
Epoch 27/50 - Loss: 0.3359 - Acc: 0.8500
Epoch 28/50 - Loss: 0.2797 - Acc: 0.8865
Epoch 29/50 - Loss: 0.3137 - Acc: 0.8615
Epoch 30/50 - Loss: 0.3019 - Acc: 0.8760
Epoch 31/50 - Loss: 0.3272 - Acc: 0.8719
Epoch 32/50 - Loss: 0.3234 - Acc: 0.8375
Epoch 33/50 - Loss: 0.3011 - Acc: 0.8854
Epoch 34/50 - Loss: 0.2955 - Acc: 0.8823
Epoch 35/50 - Loss: 0.2917 - Acc: 0.8760
Epoch 36/50 - Loss: 0.2795 - Acc: 0.8781
Epoch 37/50 - Loss: 0.2960 - Acc: 0.8938
Epoch 38/50 - Loss: 0.2591 - Acc: 0.8896
Epoch 39/50 - Loss: 0.2891 - Acc: 0.8646
Epoch 40/50 - Loss: 0.2843 - Acc: 0.8885
Epoch 41/50 - Loss: 0.2978 - Acc: 0.8688
Epoch 42/50 - Loss: 0.3037 - Acc: 0.8719
Epoch 43/50 - Loss: 0.2892 - Acc: 0.8781
Epoch 44/50 - Loss: 0.2635 - Acc: 0.9052
Epoch 45/50 - Loss: 0.2798 - Acc: 0.8938
Epoch 46/50 - Loss: 0.3359 - Acc: 0.8542
Epoch 47/50 - Loss: 0.2842 - Acc: 0.8896
Epoch 48/50 - Loss: 0.2573 - Acc: 0.9062
Epoch 49/50 - Loss: 0.3006 - Acc: 0.8781
Epoch 0/50 - Loss: 0.3015 - Acc: 0.8885
Epoch 1/50 - Loss: 0.2981 - Acc: 0.8771




`model.pth` 和 `model.onnx` 是两种不同的模型保存格式，分别用于不同的用途。

1. **model.pth:**
   - **格式：** PyTorch 模型的二进制保存格式。
   - **用途：** 适用于在 PyTorch 中加载和继续训练、进行推理或进行模型微调。
   - **内容：** 包含了模型的权重、结构以及其他相关信息。
   - **加载：** 使用 `torch.load` 方法加载，然后可以通过模型对象进行推理或者继续训练。

2. **model.onnx:**
   - **格式：** Open Neural Network Exchange (ONNX) 是一种开放的、跨平台的模型表示格式。
   - **用途：** 适用于在不同深度学习框架之间转换模型，例如在 PyTorch 到 TensorFlow 的转换。也可以用于在不同硬件和平台上进行推理，因为ONNX是跨平台的。
   - **内容：** 包含了模型的结构、权重以及计算图等信息，是一个通用的中间表示。
   - **加载：** 使用 ONNX Runtime 或其他 ONNX 支持的库进行加载，而不是直接在 PyTorch 中加载。

总的来说，`model.pth` 是 PyTorch 特有的保存格式，适用于 PyTorch 中的加载和使用，而 `model.onnx` 是一个通用的、跨平台的模型表示格式，可用于在不同框架之间转换模型或在不同平台上进行推理。